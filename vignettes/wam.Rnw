%semantic differences between near synonyms (cf., e.g., Church & Hanks 1990).
%p. 216

% for the identification of subtle semantic differences between near-synonyms (cf. Manning & Schütze 2000: 153).
%p. 216

%In a series of papers, Church and his collaborators address these problems and argue in favor of statistical, information-theoretical methods of quanti- fying (significant) degrees of association between words (i.e. degrees of collo- cational strength) (Church et al. 1990, 1991, 1994). However, while the basic argument is by now generally accepted, it is far from clear which method is optimally suited for linguistic research, and Church et al.’s work has triggered a number of studies proposing a variety of measures for this purpose (cf. Dun- ning (1993), Pedersen (1996); cf. Oakes (1998) as well as Manning & Schütze (2000) for overviews).

%Stefanowitch et Gries 2003 : 217

%(e.g. Berry-Rogghe’s (1974) z-score, Church et al.’s (1991) t-score).
%Stefanowitch et Gries 2003 : 217

%Second, some statistics are particularly prone to strongly overestimating association strengths and/or underestimating the probability of error when extremely rare collocations are investigated (e.g. MI)

% Dunning’s (1993) log-likelihood coefficient

%(cf. e.g. Church and Hanks 1990; Clear 1993; Stubbs 1995; Manning
% and Schütze 2001; see also Evert and Krenn 2001; Evert 2004)
% http://www.anglistik.uni-muenchen.de/personen/professoren/schmid/schmid_publ/collostructional-analysis.pdf

\documentclass{article}
%\VignetteIndexEntry{Introduction to lexicalStat}
\usepackage{lmodern}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{dcolumn}
%\usepackage[francais]{babel}

\makeindex

\title{wam package: computing Word association measure}

\author{Bernard Desgraupes and Sylvain Loiseau\\
<bernard.desgraupes@u-paris10.fr>, <sylvain.loiseau@univ-paris13.fr>}

\date{\today}

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle

\begin{abstract}

\end{abstract}

\vspace{5mm}
\hrule
\tableofcontents
\vspace{5mm}
\hrule

\newpage

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Introduction: Indicators of word association}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:Intro}

<<wam_setup, echo=FALSE>>=
library(wam);
@

This package contains

\begin{itemize}
\item implementations of several functions for computing word association strength ;
\item a hig level set of functions for conveniently apply these functions to corpora.
\end{itemize}

Word association can serve two goals:

\begin{itemize}
\item analyzing the association strength between
a word and a subcorpora
\item analyzing the association strength between two words (the tendency of these two words to co-occur).
\end{itemize}

% This four argument may be used for either:
%
% \begin{enumerate}
% \item compute the association strength \emph{between two words}, \emph{word1} and \emph{word2} (i.e. their tendency to co-occur with greater than chance frequency).
% \item compute the association strength between a word word1 and a subcorpus (i.e. the tendency for this word to appear in the subcorpus with greater than chance frequency.)
% \end{enumerate}

%The same quantitative framework can serve the two goals.
% : association between two words
% is simply the association between a word and the subcorpus made of all its
% cooccurrences with the other word.

% % ................................................................
% \subsection{Example 1 : computing the association between two words}
% % ................................................................
%
%
%
% % ................................................................
% \subsection{Example 2 : computing the association between a word and a subcorpora}
% % ................................................................

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Functions for computing words association strength}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:indicators}

% ................................................................
\subsection{Introduction}
% ................................................................

Several low-level functions allow for computing association strengh given raw frequencies and according to several indicators proposed in the literature.

All association measure functions are prefixed with "wam." and return a numeric vector indicating the association strengh.

% ................................................................
\subsection{Arguments}
% ................................................................

All word association measure functions have the first four arguments: ($N$, $n$, $K$, $k$), where:

\begin{enumerate}
	\item $N$ is the total size of the corpus
	\item $n$ is the size of the subcorpus (or the frequency of word2)
	\item $K$ is the frequency of word1
	\item $k$ is the sub-frequency of word1 in the subcorpus (or the number of co-occurrence between word1 and word2)
\end{enumerate}

Arguments are recycled.

% ................................................................
\subsection{Comparison with contingency table}
% ................................................................

These four arguments can be easily turn into the "contingency table" used in some publications:

\begin{center}
\begin{tabular}{lrrr}\hline
                & word1 & $\neg$ word1 &  Total  \\\hline
 subcorpus (or word2)      & 11  & 12      & R1  \\
 $\neg$ subcorpus (or word2)  & 21  & 22      & R2  \\
Total          & C1  & C2      & N   \\\hline
\end{tabular}
\end{center}

%where :

% \begin{itemize}
% \item         N   = total words in corpus (or subcorpus or restriction, but they are not implemented yet)
% \item         C1  = frequency of the collocate in the whole corpus
% \item         C2  = frequency of words that aren't the collocate in the corpus
% \item         R1  = total words in window
% \item         R2  = total words outside of window
% \item         11 = how many of collocate there are in the window
% \item         12 = how many words other than the collocate there are in the window (calculated from row total)
% \item         21 = how many of collocate there are outside the window
% \item         22 = how many words other than the collocate there are outside the window
% \end{itemize}

Conversion from $N$, $n$, $K$, $k$ :

\begin{center}
\begin{tabular}{lrrr}\hline
                        & word1 & $\neg$ word1    & Total   \\\hline
         subcorpus (or word2)      & $k$    & $n-k$         & $n$   \\
         $\neg$ subcorpus (or word2)  & $K-k$  & $N-K-(n-k)$   & $N-n$ \\
         Total         & $K$    & $N-K$         & $N$   \\\hline
\end{tabular}
\end{center}

Conversion to $N$, $n$, $K$, $k$ :

\itemize{
  \item $N = N$
  \item $n = O11 + O12$
  \item $K = O11 + O21$
  \item $k = O11$
}

The functions \texttt{contingency} and \texttt{marginal} help converting from one format toward the other.

% % ................................................................
% \subsection{TODO Documentation of the section below}
% % ................................................................
%
% All word association functions will be illustrated with data from the robespierre dataset.
% We will consider the subfrequency of the lexical types \emph{peuple}
% in a subcorpora containing the fourth discourse by Robespierre. Is this type over- or under-represented in this discouse,
% according to its frequency in the corpus of all the discourses?
%

%
% %         N  word1   n    word2   K  k
% %1 15000000 doctor 621 honorary 111 12
%
% A graph of the function is provided for all the possible values of $k$. The interval of
% the possible value of $K$ is $[0, min(k,n)]$. (it is not possible to have more
% occurrences of the lexical type than the size of the subcorpus or more than
% the total frequency of the type in the whole corpus).
%

%
% The expected subfrequency of "peuple" in the subcorpus D4 (the fourth discourse
% by Robespierre) is: $K \times n / N$.
%
%
% A form is over-used (attracted) if the subfrequency $k$ in the subcorpus is
% greater than the expected expected frequency and under-used otherwise.
% Here, the form \emph{peuple} is under-represented.

% ................................................................
\subsection{Comparison between function}
% ................................................................

TODO : max, mode (expected) for each function, negative or positive, etc.

The indicator, unless otherwise stated in the help pages of the functions, are positive when word1 is over-represented ("attracted"), and negative when word1 is under-represented.

In absolute value, the more the word is over-representend or under-represented, the more the association measure is high.

<<wam_argument_setup, echo=TRUE, fig=FALSE>>=
data(robespierre, package="wam")
head(robespierre)

peuple_D4 <- robespierre[robespierre$types=="peuple" & robespierre$parts == "D4",]
peuple_D4
N <- peuple_D4$N
n <- peuple_D4$n
K <- peuple_D4$K
k <- peuple_D4$k
maxk <- min(K,n)
maxk
allk <- 0:maxk

expected = round(K * n / N)
expected
@

<<comparison, echo=FALSE, fig=TRUE, width=4, height=8>>=
# data(ar)
# ar <- ar[1,]
# attach(ar)
op <- par(mfrow = c(4, 2)) #pty = "s", fin =c(4,6)
x <- "frequency"
y <- "Association strength"
# square plotting region,independent of device size

plot(1:K, wam.MI(N, n, K, 1:K), type="l", main="Mutual information", xlab = x, ylab = y)
points(expected, wam.MI(N, n, K, expected))

plot(1:K, wam.specificities(N, n, K, 1:K), type="l", main="Specificities", xlab = x, ylab = y)
points(expected, wam.specificities(N, n, K, expected))

plot(1:K, wam.jaccard(N, n, K, 1:K), type="l", main="Jaccard", xlab = x, ylab = y)
points(expected, wam.jaccard(N, n, K, expected))

plot(1:K, wam.loglikelihood(N, n, K, 1:K), type="l", main="Loglikelihood", xlab = x, ylab = y)
points(expected, wam.loglikelihood(N, n, K, expected))

plot(1:K, wam.z(N, n, K, 1:K), type="l", main="Z", xlab = x, ylab = y)
points(expected, wam.z(N, n, K, expected))

plot(1:K, wam.t(N, n, K, 1:K), type="l", main="T", xlab = x, ylab = y)
points(expected, wam.t(N, n, K, expected))

plot(1:K, wam.chisq(N, n, K, 1:K), type="l", main="Chi square", xlab = x, ylab = y)
points(expected, wam.chisq(N, n, K, expected))

#plot(1:K, wam.collostruction(N, n, K, 1:K), type="l", main="Collostruction", xlab = x, ylab = y)
#points(expected, wam.collostruction(N, n, K, expected))

par(op)
@

% ................................................................
\subsection{Log-likelihood}
% ................................................................
\label{sec:log-likelihood}

See Dunning 1993.

<<wam_loglikelihood, echo=TRUE, fig=FALSE>>=
wam.loglikelihood(N, n, K, k);
expected <- round(K * n / N)
wam.loglikelihood(N, n, K, expected);
@

Graph of the function :

<<wam_loglikelihood_graph, echo=TRUE, fig=TRUE>>=
maxk <- min(K,n)
maxk
allk <- 0:maxk

plot(wam.loglikelihood(N, n, K, allk),
     type="l", xlab="k", ylab="Log likelihood",
	  main="Graph of the Log likelihood function",
	  sub="(N=61449, n=7896, K=296)")
points(k, wam.loglikelihood(N, n, K, k), pch="+")
points(expected, wam.loglikelihood(N, n, K, expected), pch="x")
legend("right",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
@

% ................................................................
\subsection{Specificities}
% ................................................................
\label{sec:specificities}

See Lafon 1980.

<<wam_specificities, echo=TRUE, fig=FALSE>>=
wam.specificities(N, n, K, k, method="base");
wam.specificities(N, n, K, expected, method="base");
@

Graph of the function:

<<wam_specificities_graph, echo=TRUE, fig=TRUE>>=
plot(wam.specificities(N, n, K, allk, method="base"),
     type="l", xlab="k", ylab="specificities",
	  main="Graph of the specificities function",
	  sub="(N=61449, n=7896, K=296)")
points(k, wam.specificities(N, n, K, k, method="base"), pch="+")
points(expected, wam.specificities(N, n, K, expected, method="base"), pch="x")
legend("top",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
@

% ................................................................
\subsubsection{Analysis of the specificities indicator : Standard indicator (method="base")}
% ................................................................

The presentation below follows (Lafon, 1980).

The specificities indicator is based on the hypergeometric distribution. This distribution
give the probability associated with a drawing without replacement.

For all the possible subfrequencys of \emph{peuple}
in the fourth discourses we can compute the density of probability in the hypergeometric distribution.
The graph contains also the observed frequency as well as the mode. The mode
is the closest positive integers to the expected frequency.

<<wam_specificities_presentation3, echo=TRUE, fig=TRUE>>=
mode <- floor((n+1)*(K+1)/(N+2));
mode

plot(dhyper(allk, K, N-K, n),
type="l", xlab="k (possible subfrequency of peuple)", ylab="Density of probability",
main="Hypergeometric distribution", sub="density fonction")
points(k, dhyper(k, K, N-K, n), pch="+")
points(mode, dhyper(mode, K, N-K, n), pch="x")
@

If the observed frequency is less than the expected frequency, we compute the sum of the
probability for a frequency lesser or equal to the observed frequency ($Prob(X \leq k)$)
-- that is, the cumulative probability.

If the observed frequency is greater than the expected frequency, we compute the sum of the
probability for a frequency greater to the observed frequency ($Prob(X > k)$) (Lafon 1980 : 141) --
that is, the cumulative probability for the upper tail of the distribution.

<<wam_specificities_presentation5, echo=TRUE, fig=TRUE>>=
y <- ifelse(allk <= mode, phyper(allk, K, N-K, n),
                          phyper(allk-1, K, N-K, n, lower.tail=FALSE))
plot(allk, y,
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="Cumulative probability",
	main="Hypergeometric distribution",
	sub="lower tail for k < mode, upper tail for k >= mode")
@

We add a sign: negative if the frequency is lower than expected, positive if it is greater.

<<wam_specificities_presentation5b, echo=TRUE, fig=TRUE>>=
y <- ifelse(allk <= mode, phyper(allk, K, N-K, n),
                       phyper(allk-1, K, N-K, n, lower.tail=FALSE))
y <- ifelse(allk <= mode, -y, y);
plot(allk, y,
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="Cumulative probability",
	main="Hypergeometric distribution",
	sub="-(lower tail) for k < mode, upper tail for k >= mode")
@

It is the standard Specificities function (Lafon 1980),
as implemented in the function wam.specificities with method="base" :

<<wam_specificities_presentation5c, echo=TRUE, fig=TRUE>>=
plot(allk, wam.specificities(N, n, K, allk, method="base"),
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="Specificities",
	main="Specificities word association measure")
@

% ................................................................
\subsubsection{Analysis of the specificities indicator : log (method="log")}
% ................................................................

In order to ease the reading, log are used:

<<wam_specificities_presentation6, echo=TRUE, fig=TRUE>>=
y <- ifelse(allk <= mode, phyper(allk, K, N-K, n, log.p=TRUE),
                       phyper(allk-1, K, N-K, n, lower.tail=FALSE, log.p=TRUE))
y <- ifelse(allk <= mode, -abs(y), abs(y));
plot(allk, y,
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="log probability of hypergeometric distribution",
	main="Log-Specificities function");
points(k, phyper(k, K, N-K, n, log.p=TRUE), , pch="+")
points(mode, phyper(mode, K, N-K, n, log.p=TRUE), pch="x")
@

Another issue is that the mode is different from $0$:

<<wam_specificities_presentation6b, echo=TRUE, fig=FALSE>>=
phyper(mode, K, N-K, n, log.p=TRUE)
@

in order to have $mode = 0$, the value of the mode is substracted from all values:

<<wam_specificities_presentation7, echo=TRUE, fig=TRUE>>=
y <- ifelse(allk <= mode, phyper(allk, K, N-K, n, log.p=TRUE),
                       phyper(allk-1, K, N-K, n, lower.tail=FALSE, log.p=TRUE))
cdmo <- phyper(mode, K, N-K, n, log.p=TRUE);
y <- ifelse(allk <= mode, -abs(cdmo-y), abs(cdmo-y));
plot(allk, y,
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="log probability of hypergeometric distribution",
	main="Specificities")
points(k, wam.specificities(N, n, K, k, method="log"), pch="+")
points(mode, wam.specificities(N, n, K, mode, method="log"), pch="x")
@

That is the wam.specificities function with method="log":

<<wam_specificities_presentation8, echo=TRUE, fig=TRUE>>=
plot(allk, wam.specificities(N, n, K, allk, method="log"),
	type="l", xlab="k (possible subfrequency of peuple)",
	ylab="log probability of hypergeometric distribution",
	main="Specificities")
points(k, wam.specificities(N, n, K, k, method="log"), pch="+")
points(mode, wam.specificities(N, n, K, mode, method="log"), pch="x")
@

where the mode is $0$ :

<<wam_specificities_presentation9, echo=TRUE, fig=FALSE>>=
wam.specificities(N, n, K, mode, method="log");
@

% \begin{tabular}{l|rrrrrrr}\hline
% Discours & N & n & K & k & expected & $k > expected$ & cumulative extreme probability\\\hline
% 4 & 61449 & 6903 & 296 & 14 & \Sexpr{sprintf("%.2f", round(292 * 6903 / 61449, 2))} & $-$ & \Sexpr{sprintf("%.10f", phyper(14, 296, 61449-296, 6903))}\\
% 5 & 61449 & 7896 & 296 & 53 & \Sexpr{sprintf("%.2f", round(292 * 7896 / 61449, 2))} & $+$ & \Sexpr{sprintf("%.10f", 1 - phyper(53-1, 296, 61449-296, 7896))}\\
% 8 & 61449 & 2063 & 296 & 16 & \Sexpr{sprintf("%.2f", round(292 * 2063 / 61449, 2))} & $+$ & \Sexpr{sprintf("%.10f", 1 - phyper(16-1, 296, 61449-296, 2063))}\\\hline
% \end{tabular}
%
% According to this indicator, the second case is more "surprising" than the third or, in other
% terms, \emph{peuple} is more attracted by, or specific to the second discourse than to the third.
%
% According to relative frequency, one could conclude the other way around:
% $ 53 / 7896 = \Sexpr{round(53 / 7896, 4)} < 16 / 2063 = \Sexpr{round(16 / 2063, 4)}$
% (cf. Lafon 1980 : 152).
%
% For the fifth discourse above ($N=61449$, $n=7896$), the possible frequencies of
% \emph{peuple} range from $0$ to $296$ (if all occurrences of \emph{peuple}
% where in this discours). Here is the corresponding values for the specificities
% indicator:

% % ----------------------------------------------------------------
% % ----------------------------------------------------------------
% \section{Comparison of indicators}
% % ----------------------------------------------------------------
% % ----------------------------------------------------------------
% \label{sec:comparison-indicators}
%
% TODO
%
% % <<wam_comparison_indicators, echo=FALSE, fig=TRUE>>=
% % par(mfrow=c(1,2))
% % plot(wam.loglikelihood(61449, 7896, 296, 0:296), type="l", xlab="k", ylab="specificities", main="Log likelihood", sub="N=61449, n=7896, K=296")
% % plot(wam.specificities(61449, 7896, 296, 0:296, method="log"), type="l", xlab="k", ylab="specificities", main="Specificities indicateur (log)", sub="N=61449, n=7896, K=296")
% % @

% % ----------------------------------------------------------------
% % ----------------------------------------------------------------
% \section{Distribution of the specificities of a form across sub-corpus}
% % ----------------------------------------------------------------
% % ----------------------------------------------------------------
% \label{sec:distribution-subcorpus}
%
% TODO
%
% <<wam_distribution, echo=FALSE, fig=FALSE>>=
% #library(rcqp);
% #c <- corpus("DICKENS");
% #x <- cqp_ftable(c, "book", "lemma");
% #z <- cast(x, lemma~book, fun.aggregate=sum, value="freq")
% #F <- rowSums(z);
% #
% ##N <- sum(x$freq);
% ##f <- x[x[,1] == "1", "freq"];
% ##l <- x[x[,1] == "1", "lemma"];
% ##n <- sum(f);
% ##F <- rowSums(x);
% #s <- wam.specificities(sum(F), sum(z[1]), F, x[1])
% #hist(s, breaks=100);
% @

% ................................................................
\subsection{z}
% ................................................................
\label{sec:z}

<<wam_z, echo=TRUE, fig=FALSE>>=
wam.z(N, n, K, k);
wam.z(N, n, K, mode);
@

Graph of the function :

<<wam_z_graph, echo=TRUE, fig=TRUE>>=
plot(wam.z(N, n, K, allk),
     type="l", xlab="k", ylab="Z",
	  main="Z",
	  sub="(N=61449, n=7896, K=296)")
points(k, wam.z(N, n, K, k), pch="+")
points(mode, wam.z(N, n, K, mode), pch="x")
legend("right",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
@

% ................................................................
\subsection{t}
% ................................................................
\label{sec:t}

See Church et al. 1991.

<<wam_t, echo=TRUE, fig=FALSE>>=
wam.t(N, n, K, k);
wam.t(N, n, K, mode);
@

Graph of the function :

<<wam_t_graph, echo=TRUE, fig=TRUE>>=
plot(allk, wam.t(N, n, K, allk),
     type="l", xlab="k", ylab="T",
	  main="t",
	  sub="(N=61449, n=7896, K=296)")
points(k, wam.t(N, n, K, k), pch="+")
points(mode, wam.t(N, n, K, mode), pch="x")
legend("right",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
@

% ................................................................
\subsection{chisq}
% ................................................................
\label{sec:chisq}

<<wam_chisq, echo=TRUE, fig=FALSE>>=
wam.chisq(N, n, K, k);
wam.chisq(N, n, K, mode);
@

Graph of the function :

<<wam_chisq_graph, echo=TRUE, fig=TRUE>>=
plot(allk, wam.chisq(N, n, K, allk),
     type="l", xlab="k", ylab="Chi square",
	  main="Chi square",
	  sub="(N=61449, n=7896, K=296)")
points(k, wam.chisq(N, n, K, k), pch="+")
points(mode, wam.chisq(N, n, K, mode), pch="x")
legend("right",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
@

% ................................................................
\subsection{collostruction}
% ................................................................
\label{sec:collostruction}

<<wam_collostruction, echo=TRUE, fig=FALSE>>=
#wam.collostruction(N, n, K, k);
#wam.collostruction(N, n, K, expected);
@

Graph of the function :

% <<wam_fisher_graph, echo=TRUE, fig=TRUE>>=
% # plot(allk, wam.collostruction(N, n, K, allk),
% #      type="l", xlab="k", ylab="Fisher",
% # 	  main="Fisher",
% # 	  sub="(N=61449, n=7896, K=296)")
% # points(k, wam.collostruction(N, n, K, k), pch="+")
% # points(expected, wam.collostruction(N, n, K, expected), pch="x")
% # legend("right",legend=c("k","expected"), pch=c("+","x"), cex=0.75)
% @

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{High level interface}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:indicators}

The function \emph{wam} provide a more high level interface to the actual functions.

This function allows for computing several indicators at the same time.

It takes also as argument the subcorpus name and lexical types.

<<wam_wam, echo=TRUE, fig=FALSE>>=
rm(list=ls())
data(robespierre, package="wam")
wam.res <- wam(data=robespierre, measure=c("loglikelihood", "specificities"))
@

function allows for retrieving the basic information (see the manual page for WordAssociation):

<<wam_wam2, echo=TRUE, fig=FALSE>>=
head(k(wam.res));
@

<<wam_wam2, echo=TRUE, fig=FALSE>>=
head(association(wam.res));
indicator.name(wam.res);
unique(parts(wam.res));
@

The print function allows for an easy to use reading of the results. See :

<<wam_wam3, echo=TRUE, fig=FALSE>>=
print(wam.res, from=1, to=10, parts="D4");
@

% TODO other function for printing the result.

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Bibliography}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
Kenneth Ward Church, Patrick Hanks (1990) "Word Association Norms,
Mutual Information, and Lexicography" \emph{Computational Linguistics},
16/1, pages 22-29.
\url{http://www.aclweb.org/anthology/P89-1010.pdf}

Chaudhari, D. L., Damani, O. P. \& Laxman, S. 2011. "Lexical co-occurrence, statistical significance, and word association". In: Conference on Empirical Methods in Natural Language Processing (Edinburgh, Scotland, UK, July 27-31).
pp. 1058-68

\url{http://www.aclweb.org/anthology-new/D/D11/D11-1098.pdf}

Church K., Gale W., Hanks P., Hindle D. 1991. "Using Statistics in Lexical Analysis", In: Zernik U. (ed.) Lexical Acquisition: Exploiting on-line resources to build a lexicon. Hillsdale NJ: Lawrence Erlbaum, pp. 115-164.

Dunning, T. 1993. "Accurate methods for the statistics of surprise and coincidence." In: Computational Linguistics. 19(1). Pp 61--74.

\url{http://acl.ldc.upenn.edu/J/J93/J93-1003.pdf}

Hofland, K. and Johanssen, S. 1989. Frequency analysis of English vocabulary and grammar, based on the LOB corpus. Oxford: Clarendon.

Kilgarriff, A. 1996. "Which words are particularly characteristic of a text? A survey of statistical approaches." In: Proceedings, ALLC-ACH '96. Bergen, Norway.

\url{http://www.cse.iitb.ac.in/~shwetaghonge/prec_recall.pdf}

Lafon P. 1980. "Sur la variabilit? de la fr?quence des formes dans un corpus". \emph{Mots}, 1, 1980, 127--165.

\url{http://www.persee.fr/web/revues/home/prescript/article/mots_0243-6450_1980_num_1_1_1008}.

Stefanowitsch A. \& Gries St. Th. 2003 "Collostructions: Investigating the interaction of words and constructions", \emph{International Journal of Corpus Linguistics}, 8/2, 209-234.

\printindex

\end{document}

